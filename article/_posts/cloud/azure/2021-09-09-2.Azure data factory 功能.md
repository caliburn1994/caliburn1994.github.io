---
layout: post 
title: Azure - 2.Azure Data Facotry 功能一栏
tags: Cloud
comments: 1 
excerpt: Aazure Data Facotry的笔记-2 功能一栏
typora-root-url: ..\..\..\..
typora-copy-images-to: ..\..\..\..\assets\blog_res\azure
---

## Copy Activity

### 概念

source: 数据源

[sink](https://en.wikipedia.org/wiki/Sink_(computing)): 接收器 (原意: 水槽，洗碗槽)

Hierarchical  分层：JSON、XML、NoSQL

tabular : 表格（excel、关系数据库）

### 性能

概念📙

DIU (Data Integration Unit) [^1]这是 Azure云 特有的概念，介绍的文档比较少且模糊不清，笔者认为应解释为 "单位时间内，CPU、内存、网络资源分配等消耗的时间"

策略♞

-  [For Each ](https://docs.microsoft.com/en-us/azure/data-factory/control-flow-for-each-activity) 并行执行，并修改 BatchCount，使之可高并行。
-  Copy Activity 的性能
  ![监视复制活动运行详细信息](/assets/blog_res/azure/monitor-copy-activity-run-details.png)
  1. Azure 提供了[性能优化 (performance tuning) 提示](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-troubleshooting)功能
     - [并行数的调优](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-features#parallel-copy)
     - [颗粒大小的调优](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-features#data-integration-units)
  2. **Duration** 的内容常为优化的对象。[^3]
  3. [暂存 (staging) 功能](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-features#staged-copy)  (Specify whether to copy data via an interim staging store. Enable staging only for the beneficial scenarios, e.g. load data into Azure Synapse Analytics via PolyBase, load data to/from Snowflake, load data from Amazon Redshift via UNLOAD or from HDFS via DistCp, etc.[Learn more](https://go.microsoft.com/fwlink/?linkid=2159335))

### Schema映射  Schema Mapping

Copy Activity 有一系列默认的映射策略。而配置显式映射 (Explicit mapping) 时，需加注意，不同的 source-sink 组合配置的方式是不同。[^2]

![从表格映射到表格](/assets/blog_res/azure/map-tabular-to-tabular.png)

Mapping 支持 *Fatten* 操作，可以讲一个 array 扁平化。这方便 JSON 转换成 table

![使用 UI 从分层映射到表格](/assets/blog_res/azure/map-hierarchical-to-tabular-ui.png)







### 数据一致性验证 Data consistency verification

Copy Activity 提供了数据<div class='sup' data-title="以确保数据不仅成功地从源存储复制到目标存储，而且验证了源存储和目标存储之间的一致性。">一致性验证</div>。通过 `validateDataConsistency` 启动该校验。[^5]

校验的*对象*以及*策略*♘

- 二进制对象：file size, lastModifiedDate, MD5 checksum 
- 表格数据（tabular data）：` 读取的行数 = 复制的行数 + 跳过的行数`

*什么时候发生？*📅[^4]

- 主键重复
- 作为 source 的二进制文件不能访问、被删除

当数据发生 *不一致性*⚠️时，可以通过 `dataInconsistency` 设置行为

- 中止
- 跳跃

在设定 `logSettings` 和 `path` 可以记录 *不一致* 时候的日志。

### 监控·容错·测试 Monitor·Fault tolerance·Test

💿数据不一致

当 *不允许数据不一致* 那么 Copy Activity 将重试或者中止。中止时，pipeline 将以失败的形式返回，此时可以

1. 发送邮件通知
2. 定期查看 监控 (monitor) 情况 

当 *允许数据不一致* 时，可以监控以下数据，并根据所得数据进行下一步策略下一步策略。[^4]

- activity结果 (`@activity('Copy data').output`) [^6]
- 日志文件

📏测试

可通过来回复制进行数据校验进行实现，示例如下: 

1. 备份 数据库-1 至 Azure Blob Storage
2. Azure Blob Storage 将备份数据恢复至 数据库-2
3. 数据库-1 和 数据库-2 的数据进行一一比较。

目的: 数据在传输中是否有不可预料损失和变形。

📝特殊需求

监控 Copy Activity 的运行时长，当时长过长时，发送监控信息至运维人员。[^6]

### 其他

- 压缩功能

## Delete Activity 

Delete Activity 仅仅用于删除文件。如需定时删除文件，则要与 schedule trigger 一起使用



## 参考 References

[^1]: [Data Integration Units](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-features#data-integration-units)
[^2]: [Schema and data type mapping in copy activity - Microsoft Docs](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-schema-and-type-mapping)

[^3]:[Troubleshoot copy activity on Azure IR](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-performance-troubleshooting#troubleshoot-copy-activity-on-azure-ir)
[^4]: [Fault tolerance](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-fault-tolerance)
[^5]: [Data consistency verification in copy activity - Azure](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-data-consistency)
[^6]: [Monitor copy activity](https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-monitoring)